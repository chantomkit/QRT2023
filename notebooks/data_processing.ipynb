{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, boxcox, pearsonr, ks_2samp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import json\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "def metric_train(output, truth):\n",
    "    return spearmanr(output, truth).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXOTIC_PATH = \"data/processed/exotic\"\n",
    "NON_EXOTIC_PATH = \"data/processed/non_exotic\"\n",
    "FULL_PATH = \"data/processed/full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1494, 34), (1494, 1), (654, 34))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"data/raw/X_train_NHkHMNU.csv\").set_index(\"ID\")\n",
    "y_train = pd.read_csv(\"data/raw/y_train_ZAN5mwg.csv\").set_index(\"ID\")\n",
    "X_test = pd.read_csv(\"data/raw/X_test_final.csv\").set_index(\"ID\")\n",
    "\n",
    "feature_cols = X_train.columns.drop([\"DAY_ID\", \"COUNTRY\"]).to_list()\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = {\"FR\": 0, \"DE\": 1}\n",
    "\n",
    "full_train = y_train.join(X_train)\n",
    "full_train = full_train.replace(country_code)\n",
    "\n",
    "full_train[\"RANK\"] = full_train[\"TARGET\"].rank()\n",
    "\n",
    "X_test = X_test.replace(country_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_exotic_idx(df: pd.DataFrame):\n",
    "    day_count = df.groupby(\"DAY_ID\")[\"COUNTRY\"].count()\n",
    "    exotic_day = day_count[day_count == 1].index.to_list()\n",
    "    non_exotic_day = day_count[day_count == 2].index.to_list()\n",
    "    return exotic_day, non_exotic_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exotic_train_idx, non_exotic_train_idx = split_exotic_idx(full_train)\n",
    "exotic_train_df = full_train.loc[full_train[\"DAY_ID\"].isin(exotic_train_idx)]\n",
    "non_exotic_train_df = full_train.loc[full_train[\"DAY_ID\"].isin(non_exotic_train_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exotic_test, non_exotic_test = split_exotic_idx(X_test)\n",
    "exotic_test_X = X_test.loc[X_test[\"DAY_ID\"].isin(exotic_test)]\n",
    "non_exotic_test_X = X_test.loc[X_test[\"DAY_ID\"].isin(non_exotic_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DE_FR_EXCHANGE', 'FR_DE_EXCHANGE', 'DE_NET_EXPORT', 'FR_NET_EXPORT',\n",
      "       'DE_NET_IMPORT', 'FR_NET_IMPORT'],\n",
      "      dtype='object')\n",
      "Index(['DE_RAIN', 'FR_RAIN', 'DE_WIND', 'FR_WIND', 'DE_TEMP', 'FR_TEMP'], dtype='object')\n",
      "Index(['DE_FR_EXCHANGE', 'FR_DE_EXCHANGE', 'DE_NET_EXPORT', 'FR_NET_EXPORT',\n",
      "       'DE_NET_IMPORT', 'FR_NET_IMPORT'],\n",
      "      dtype='object')\n",
      "Index(['DE_RAIN', 'FR_RAIN', 'DE_WIND', 'FR_WIND', 'DE_TEMP', 'FR_TEMP'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(exotic_train_df.columns[exotic_train_df.isna().any(axis=0) != 0])\n",
    "print(non_exotic_train_df.columns[non_exotic_train_df.isna().any(axis=0) != 0])\n",
    "print(exotic_test_X.columns[exotic_test_X.isna().any(axis=0) != 0])\n",
    "print(non_exotic_test_X.columns[non_exotic_test_X.isna().any(axis=0) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median fillna\n",
    "exotic_train_df = exotic_train_df.fillna(exotic_train_df.median())\n",
    "exotic_test_X = exotic_test_X.fillna(exotic_test_X.median())\n",
    "\n",
    "def fill_median_by_country(df: pd.DataFrame, df_fit: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    median_filler = df_fit.loc[df_fit.COUNTRY == 0].median()\n",
    "    df.loc[df.COUNTRY == 0] = df.loc[df.COUNTRY == 0].fillna(median_filler)\n",
    "    median_filler = df_fit.loc[df_fit.COUNTRY == 1].median()\n",
    "    df.loc[df.COUNTRY == 1] = df.loc[df.COUNTRY == 1].fillna(median_filler)\n",
    "    return df\n",
    "\n",
    "non_exotic_train_df = fill_median_by_country(non_exotic_train_df, non_exotic_train_df)\n",
    "non_exotic_test_X = fill_median_by_country(non_exotic_test_X, non_exotic_train_df)\n",
    "\n",
    "full_train = fill_median_by_country(full_train, full_train)\n",
    "X_test = fill_median_by_country(X_test, full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE = \"median_imputed\"\n",
    "# exotic_train_df.to_csv(f\"{EXOTIC_PATH}/{STAGE}_train.csv\")\n",
    "# exotic_test_X.to_csv(f\"{EXOTIC_PATH}/{STAGE}_test.csv\")\n",
    "# non_exotic_train_df.to_csv(f\"{NON_EXOTIC_PATH}/{STAGE}_train.csv\")\n",
    "# non_exotic_test_X.to_csv(f\"{NON_EXOTIC_PATH}/{STAGE}_test.csv\")\n",
    "# full_train.to_csv(f\"{FULL_PATH}/{STAGE}_train.csv\")\n",
    "# X_test.to_csv(f\"{FULL_PATH}/{STAGE}_test.csv\")\n",
    "\n",
    "def save_by_region(df, path):\n",
    "    df.loc[df.COUNTRY == 0].to_csv(f\"{path}_fr.csv\")\n",
    "    df.loc[df.COUNTRY == 1].to_csv(f\"{path}_de.csv\")\n",
    "    return\n",
    "\n",
    "# save_by_region(non_exotic_train_df, f\"{NON_EXOTIC_PATH}/{STAGE}_train\")\n",
    "# save_by_region(non_exotic_test_X, f\"{NON_EXOTIC_PATH}/{STAGE}_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_interactions(df):\n",
    "    pf = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "    val = pf.fit_transform(df)\n",
    "    cols = pf.get_feature_names_out()\n",
    "    return pd.DataFrame(data=val, columns=cols).set_index(df.index)\n",
    "\n",
    "non_exotic_train_d2_feat = add_interactions(non_exotic_train_df[feature_cols])\n",
    "exotic_train_d2_feat = add_interactions(exotic_train_df[feature_cols])\n",
    "\n",
    "non_exotic_test_d2_feat = add_interactions(non_exotic_test_X[feature_cols])\n",
    "exotic_test_d2_feat = add_interactions(exotic_test_X[feature_cols])\n",
    "\n",
    "feature_cols_d2 = non_exotic_train_d2_feat.columns.to_list()\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_feat_cols = [\"DAY_ID\", \"COUNTRY\", \"TARGET\", \"RANK\"]\n",
    "non_exotic_train_df = non_exotic_train_df[non_feat_cols].join(non_exotic_train_d2_feat)\n",
    "exotic_train_df = exotic_train_df[non_feat_cols].join(exotic_train_d2_feat)\n",
    "\n",
    "non_feat_cols = [\"DAY_ID\", \"COUNTRY\"]\n",
    "non_exotic_test_X = non_exotic_test_X[non_feat_cols].join(non_exotic_test_d2_feat)\n",
    "exotic_test_X = exotic_test_X[non_feat_cols].join(exotic_test_d2_feat)\n",
    "\n",
    "# STAGE = \"median_imputed_d2\"\n",
    "# exotic_train_df.to_csv(f\"{EXOTIC_PATH}/{STAGE}_train.csv\")\n",
    "# exotic_test_X.to_csv(f\"{EXOTIC_PATH}/{STAGE}_test.csv\")\n",
    "# non_exotic_train_df.to_csv(f\"{NON_EXOTIC_PATH}/{STAGE}_train.csv\")\n",
    "# non_exotic_test_X.to_csv(f\"{NON_EXOTIC_PATH}/{STAGE}_test.csv\")\n",
    "\n",
    "# save_by_region(non_exotic_train_df, f\"{NON_EXOTIC_PATH}/{STAGE}_train\")\n",
    "# save_by_region(non_exotic_test_X, f\"{NON_EXOTIC_PATH}/{STAGE}_test\")\n",
    "\n",
    "len(non_exotic_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_exotic_train_df_fr = non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 0]\n",
    "non_exotic_train_df_de = non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 1]\n",
    "\n",
    "non_exotic_test_X_fr = non_exotic_test_X.loc[non_exotic_test_X.COUNTRY == 0]\n",
    "non_exotic_test_X_de = non_exotic_test_X.loc[non_exotic_test_X.COUNTRY == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_dist(df1: pd.DataFrame, df2: pd.DataFrame, pvalue=0.05, features=feature_cols_d2):\n",
    "    return [col for col in features if ks_2samp(df1[col], df2[col]).pvalue < pvalue]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very lazy KS test that shows the dataset compose of \"three\" sets\n",
    "- France (\"non-exotic\")\n",
    "- Germany (\"non-exotic\")\n",
    "- France (\"exotic\", Germany does not have these DAY_IDs)\n",
    "\n",
    "Summary:\n",
    "- Features are the same for non-exotic France and non-exotic Germany\n",
    "- Features distributions are different for non-exotic and exotic\n",
    "- Targets distribution is different for non-exotic France and non-exotic Germany\n",
    "- Targets distribution is the same for non-exotic and exotic France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features having different distributions for FR non-exotic and DE non-exotic: 0\n",
      "Number of features having different distributions for non-exotic and exotic: 403\n",
      "Number of features having different distributions for FR non-exotic and exotic: 386\n",
      "Number of features having different distributions for DE non-exotic and exotic: 386\n",
      "FR non-exotic and DE non-exotic target sharing different distribution? True\n",
      "FR non-exotic and exotic target sharing different distribution? False\n",
      "DE non-exotic and exotic target sharing different distribution? True\n"
     ]
    }
   ],
   "source": [
    "# Non-exotic X's are same dist\n",
    "ks_non_exotic = different_dist(non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 0], non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 1])\n",
    "print(\n",
    "    \"Number of features having different distributions for FR non-exotic and DE non-exotic:\", \n",
    "    len(ks_non_exotic)\n",
    ")\n",
    "# Exotic X's are different dist from non-exotic X's\n",
    "ks_exotic = different_dist(non_exotic_train_df, exotic_train_df)\n",
    "ks_fr_exotic = different_dist(non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 0], exotic_train_df)\n",
    "ks_de_exotic = different_dist(non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 1], exotic_train_df)\n",
    "print(\n",
    "    \"Number of features having different distributions for non-exotic and exotic:\", \n",
    "    len(ks_exotic)\n",
    ")\n",
    "print(\n",
    "    \"Number of features having different distributions for FR non-exotic and exotic:\", \n",
    "    len(ks_fr_exotic)\n",
    ")\n",
    "print(\n",
    "    \"Number of features having different distributions for DE non-exotic and exotic:\", \n",
    "    len(ks_de_exotic)\n",
    ")\n",
    "# Non-exotic targets are different distributions by country\n",
    "print(\n",
    "    \"FR non-exotic and DE non-exotic target sharing different distribution?\", \n",
    "    ks_2samp(\n",
    "        non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 0, \"TARGET\"], \n",
    "        non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 1, \"TARGET\"],\n",
    "    ).pvalue < 0.05\n",
    ")\n",
    "print(\n",
    "    \"FR non-exotic and exotic target sharing different distribution?\",\n",
    "    ks_2samp(\n",
    "        non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 0, \"TARGET\"], \n",
    "        exotic_train_df[\"TARGET\"],\n",
    "    ).pvalue < 0.05\n",
    ")\n",
    "print(\n",
    "    \"DE non-exotic and exotic target sharing different distribution?\",\n",
    "    ks_2samp(\n",
    "        non_exotic_train_df.loc[non_exotic_train_df.COUNTRY == 1, \"TARGET\"], \n",
    "        exotic_train_df[\"TARGET\"],\n",
    "    ).pvalue < 0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding features distributions drift between train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 195)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common_feature_cols = list(set(feature_cols).difference(ks_exotic))\n",
    "\n",
    "exotic_drift_cols = different_dist(exotic_train_df, exotic_test_X)\n",
    "non_exotic_drift_cols = different_dist(non_exotic_train_df, non_exotic_test_X)\n",
    "len(exotic_drift_cols), len(non_exotic_drift_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feat_selector():\n",
    "    def __init__(self, corr, target=\"TARGET\"):\n",
    "        self.corr = corr\n",
    "        self.target = target\n",
    "\n",
    "    def multi_colinear_feat(self, thres):\n",
    "        # upper triangle masking for correlation matrix\n",
    "        tri_mask = np.triu(np.ones(self.corr.shape, dtype=np.bool_))\n",
    "        # finding multicollinear variable pairs\n",
    "        multi_collin = self.corr[self.corr.mask(tri_mask).abs() > thres]\n",
    "        # extracting the pairs\n",
    "        mc_idxs = np.stack(multi_collin.notnull().values.nonzero()).T.tolist()\n",
    "        mc_cols = [[self.corr.columns[i1], self.corr.columns[i2]] for (i1, i2) in mc_idxs]\n",
    "\n",
    "        return [\n",
    "            c2 if abs(self.corr[self.target][c1]) < abs(self.corr[self.target][c2]) else c1 for c1, c2 in mc_cols\n",
    "            ]\n",
    "    \n",
    "    def weak_feat(self, thres):\n",
    "        weak_flag = self.corr[self.target].abs() < thres\n",
    "        return weak_flag.index[weak_flag].to_list()\n",
    "\n",
    "    def run(self, multi_collinear_thres=0.8, weak_thres=0.05):\n",
    "        return list(set(self.multi_colinear_feat(multi_collinear_thres) + self.weak_feat(weak_thres)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DE_COAL FR_WINDPOW             0.056917\n",
       "DE_NUCLEAR GAS_RET            -0.072557\n",
       "DE_NET_EXPORT                 -0.052830\n",
       "DE_NUCLEAR DE_RESIDUAL_LOAD   -0.054144\n",
       "DE_NET_IMPORT CARBON_RET       0.072136\n",
       "                                 ...   \n",
       "DE_COAL DE_NUCLEAR             0.060560\n",
       "GAS_RET                        0.151401\n",
       "DE_NET_EXPORT FR_GAS           0.055869\n",
       "FR_GAS FR_HYDRO                0.064794\n",
       "FR_COAL DE_TEMP                0.053265\n",
       "Name: TARGET, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing drifted features\n",
    "non_exotic_remainder = list(set(feature_cols_d2).difference(non_exotic_drift_cols))\n",
    "# feature selection by correlation\n",
    "tmp_corr = non_exotic_train_df_fr[[\"TARGET\"] + non_exotic_remainder].corr(\"spearman\")\n",
    "# Finding out the multi-collinear features, and weakly correlated features with targets\n",
    "non_exotic_fr_drop_cols = feat_selector(tmp_corr).run(multi_collinear_thres=0.7)\n",
    "# Removing them, for linear models\n",
    "non_exotic_fr_feature_cols = list(set(non_exotic_remainder).difference(non_exotic_fr_drop_cols))\n",
    "\n",
    "tmp_corr[\"TARGET\"][non_exotic_fr_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DE_COAL FR_WINDPOW             0.166102\n",
       "FR_COAL DE_LIGNITE            -0.053679\n",
       "DE_WIND                       -0.147871\n",
       "DE_WINDPOW FR_WIND            -0.086121\n",
       "FR_HYDRO FR_WINDPOW            0.065840\n",
       "                                 ...   \n",
       "FR_NET_EXPORT FR_NET_IMPORT   -0.082838\n",
       "FR_WINDPOW DE_LIGNITE          0.154410\n",
       "FR_COAL DE_RESIDUAL_LOAD      -0.188544\n",
       "DE_GAS FR_RAIN                -0.155213\n",
       "DE_WINDPOW                    -0.300933\n",
       "Name: TARGET, Length: 63, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_corr = non_exotic_train_df_de[[\"TARGET\"]+non_exotic_remainder].corr(\"spearman\")\n",
    "non_exotic_de_drop_cols = feat_selector(tmp_corr).run(multi_collinear_thres=0.7)\n",
    "non_exotic_de_feature_cols = list(set(non_exotic_remainder).difference(non_exotic_de_drop_cols))\n",
    "\n",
    "tmp_corr[\"TARGET\"][non_exotic_de_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FR_COAL DE_WINDPOW           0.185677\n",
       "FR_COAL FR_SOLAR            -0.051922\n",
       "FR_NET_EXPORT DE_COAL        0.085119\n",
       "DE_HYDRO DE_RAIN            -0.055944\n",
       "DE_RESIDUAL_LOAD COAL_RET    0.124131\n",
       "                               ...   \n",
       "FR_SOLAR GAS_RET            -0.064669\n",
       "DE_RAIN GAS_RET             -0.102447\n",
       "GAS_RET CARBON_RET          -0.077973\n",
       "FR_RAIN FR_TEMP              0.070030\n",
       "FR_NET_IMPORT CARBON_RET    -0.155249\n",
       "Name: TARGET, Length: 62, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exotic_remainder = list(set(feature_cols_d2).difference(exotic_drift_cols))\n",
    "\n",
    "tmp_corr = exotic_train_df[[\"TARGET\"]+exotic_remainder].corr(\"spearman\")\n",
    "exotic_drop_cols = feat_selector(tmp_corr).run(multi_collinear_thres=0.7)\n",
    "exotic_feature_cols = list(set(exotic_remainder).difference(exotic_drop_cols))\n",
    "\n",
    "tmp_corr[\"TARGET\"][exotic_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = {\n",
    "    \"de\": non_exotic_de_feature_cols,\n",
    "    \"fr\": non_exotic_fr_feature_cols,\n",
    "    \"exotic\": exotic_feature_cols,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize selected features for later use\n",
    "# json.dump(feature_selection, open(\"features/feature_d2_selection.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b1b51844297d35c968758913ba1b8e9c346e0ddf0da5bc15cfd46ed8ca42702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
